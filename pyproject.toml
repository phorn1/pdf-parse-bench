[project]
name = "pdf-parse-bench"
version = "0.1.0"
description = "Benchmark suite for evaluating PDF parser quality on mathematical formulas"
requires-python = ">=3.12"
dependencies = [
    # Core
    "pydantic>=2.10",
    "pydantic-settings>=2.0.0",
    "pyyaml>=6.0.0",
    "python-dotenv>=1.0.0",
    "tqdm>=4.66.0",
    "rich>=14.1.0",
    # Evaluation & AI
    "openai>=1.99.0",
    "google-genai>=1.46.0",
    "mistralai>=1.9.0",
    "requests>=2.32.0",
    "levenshtein>=0.27.1",
    "nltk>=3.9.1",
    # Used for Unicode to LaTeX conversion in formula rendering
    "pylatexenc>=2.10",

    "pymupdf>=1.24.0",
    "pillow>=10.0.0",

    # Synthetic PDF generation - for creating test documents
    "faker>=37.11.0",
    "duckdb>=1.4.1",
]

[project.optional-dependencies]

# PDF Parsers - install individually as needed
pymupdf4llm = [
    "pymupdf4llm>=0.0.17",
]

llamaparse = [
    "llama-cloud-services>=0.6.76"
]

mathpix = [
    "mpxpy>=0.0.18"
]

got_ocr2 = [
    "torch>=2.0.1",
    "torchvision>=0.15.2",
    "transformers==4.37.2",
    "tiktoken>=0.6.0",
    "verovio>=4.3.1",
    "accelerate>=0.28.0",
]

nanonets_ocr_s = [
    "torch>=2.0.1",
    "transformers>=4.37.0",
    "accelerate>=0.28.0",
]

olmocr = [
    "vllm>=0.6.0",
    "torch>=2.0.1",
]


[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["pdf_parse_bench", "parsers"]

[tool.hatch.build.targets.wheel.force-include]
"data" = "pdf_parse_bench/data"

[tool.hatch.build.targets.sdist]
include = [
    "/src",
    "/data",
]

[tool.uv]
conflicts = [
    [
        { extra = "got_ocr2" },
        { extra = "olmocr" },
    ],
]

